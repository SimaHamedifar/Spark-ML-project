{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e56c12-1617-483c-bc12-46f9abb1118a",
   "metadata": {},
   "source": [
    "## Build a Spark ML Pipeline for Airfoil noise prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark Final Project\n",
    "\n",
    "This project was created as part of the IBM Machine Learning with Apache Spark course and demonstrates Spark-based ETL, data analysis, and ML pipeline training using PySpark.\n",
    "\n",
    "All code is original, developed for learning and demonstration purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc13b47-495e-4e67-b278-0dbf10eccff0",
   "metadata": {},
   "source": [
    "## Scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c0712-50f3-471c-99c5-920a2df8ec03",
   "metadata": {},
   "source": [
    "You are a data engineer at an aeronautics consulting company. Your company prides itself in being able to efficiently design airfoils for use in planes and sports cars. Data scientists in your office need to work with different algorithms and data in different formats. While they are good at Machine Learning, they count on you to be able to do ETL jobs and build ML pipelines. In this project you will use the modified version of the NASA Airfoil Self Noise dataset. You will clean this dataset, by dropping the duplicate rows, and removing the rows with null values. You will create an ML pipe line to create a model that will predict the SoundLevel based on all the other columns. You will evaluate the model and towards the end you will persist the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1b083-663c-4bd6-99bb-b29157087191",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this lab you will be using dataset(s):\n",
    "\n",
    " - The original dataset can be found here NASA airfoil self noise dataset. https://archive.ics.uci.edu/dataset/291/airfoil+self+noise\n",
    " \n",
    " - This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d1386-3fa3-4e74-8267-b4abbad19822",
   "metadata": {},
   "source": [
    "Diagram of an airfoil. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d3a47-ce94-44fd-8b8a-6af91dc0ed73",
   "metadata": {},
   "source": [
    "![Airfoil with flow](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_with_flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caab956-545b-4329-9906-07abab5b483a",
   "metadata": {},
   "source": [
    "Diagram showing the Angle of attack. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f19c5-26d1-432a-bc7b-eb33a1797e13",
   "metadata": {},
   "source": [
    "![Airfoil angle of attack](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_angle_of_attack.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487e023-cb93-4908-96aa-841f690510a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyspark==3.1.2 -q\n",
    "%pip install findspark -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8870410-d57f-459e-82d3-e31004269253",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353c96d-ee3f-4d79-b949-1053921bc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1261fbf-b62e-4648-a41f-8ad4df422b10",
   "metadata": {},
   "source": [
    "## Part 1 - Perform ETL activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad80c49-119d-4da4-ae24-c0c3b6f32f4a",
   "metadata": {},
   "source": [
    "### Task 1 - Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b41c76-d73c-4142-9153-da81ef7fe2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, Tokenizer, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67837440-7f44-4044-8265-907db2964a7f",
   "metadata": {},
   "source": [
    "### Task 2 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc096743-b799-4486-bd59-7a2694cf240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Final Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66db79-d588-421b-bb03-2046c5f72b47",
   "metadata": {},
   "source": [
    "### Task 3 - Load the csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c921f-2a08-485a-8ead-647ae5190d8a",
   "metadata": {},
   "source": [
    "Download the data file.\n",
    "\n",
    "NOTE : Please ensure you use the dataset below and not the original dataset mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590253ae-ddc7-48de-a53b-bc1e6980557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a2bda-7ac6-4962-be66-fe264f4e393f",
   "metadata": {},
   "source": [
    "Load the dataset into the spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a2f94-61d6-4c6e-84a3-4c2ec438fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset that you have downloaded in the previous task\n",
    "\n",
    "df = spark.read.csv(\"NASA_airfoil_noise_raw.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a3281-2b98-474d-9c1a-1cb15dd8615a",
   "metadata": {},
   "source": [
    "### Task 4 - Print top 5 rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081882f7-4050-4c70-93c5-2663876eb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009ba43-caa8-4e92-93c8-36c8e3aa66fb",
   "metadata": {},
   "source": [
    "### Task 6 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc574b-6295-41f9-9746-5d5f9d93d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "rowcount1 = df.count()\n",
    "print(rowcount1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80db51-6902-40f6-812e-60333e22979b",
   "metadata": {},
   "source": [
    "### Task 7 - Drop all the duplicate rows from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0afb6-2f7b-4cae-9d4a-e1afbe8072ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4086f-ee6a-470c-85d9-b4d624c90f29",
   "metadata": {},
   "source": [
    "### Task 8 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2c12b-9b8f-48f7-8b3e-faf872e0a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "rowcount2 = df.count()\n",
    "print(rowcount2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d5e2a-1d36-4b92-8576-676d6710a0bb",
   "metadata": {},
   "source": [
    "### Task 9 - Drop all the rows that contain null values from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e52d0-27f0-4587-9cb0-e6a9574cdee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d92d50-01e7-48d6-96fc-08f331965cfc",
   "metadata": {},
   "source": [
    "### Task 10 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f52a4-bdaa-43c3-bad9-b5245f6a5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "rowcount3 = df.count()\n",
    "print(rowcount3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96848378-5624-4c42-9209-a0c2943b4364",
   "metadata": {},
   "source": [
    "### Task 11 - Rename the column \"SoundLevel\" to \"SoundLevelDecibels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda731e-4ae1-4ac8-850b-367157aaa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "df = df.withColumnRenamed(\"SoundLevel\", \"SoundLevelDecibels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104188a8-01b2-48a4-b2d7-4f9b13e38d7d",
   "metadata": {},
   "source": [
    "### Task 12 - Save the dataframe in parquet format, name the file as \"NASA_airfoil_noise_cleaned.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bbc03-dfd0-45e4-9040-2d2118eaf459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "df.write.mode(\"overwrite\").parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96bd1b-9bf7-4f29-b84a-607d2a9adde5",
   "metadata": {},
   "source": [
    "## Part - 2 Create a  Machine Learning Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5c6a7-a477-4582-a019-db83c6c83e7e",
   "metadata": {},
   "source": [
    "### Task 1 - Load data from \"NASA_airfoil_noise_cleaned.parquet\" into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71052ed6-a0b4-4597-9de0-f4bb4a39c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "df = spark.read.parquet(\"NASA_airfoil_noise_cleaned.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b9a8f-c52b-4d9a-9960-382c7980e6ca",
   "metadata": {},
   "source": [
    "### Task 2 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e8be24-c55b-4bc7-a3d0-4598e75cdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "rowcount4 = df.count()\n",
    "print(rowcount4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b4473-aed8-4a3b-b0f3-5b040113a8fe",
   "metadata": {},
   "source": [
    "### Task 3 - Define the VectorAssembler pipeline stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532cc09-f380-4ac6-89a5-67fa687459c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel\n",
    "assembler = VectorAssembler(inputCols=[\"Frequency\", \"AngleOfAttack\", \"ChordLength\", \"FreeStreamVelocity\", \"SuctionSideDisplacement\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e689bb8-a68b-4476-85b2-1d9187fdb2e6",
   "metadata": {},
   "source": [
    "### Task 4 - Define the StandardScaler pipeline stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33388fa9-57df-4037-8ad9-fc63c711bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017e200-43bd-4334-8a3e-f7a3cce8b1b6",
   "metadata": {},
   "source": [
    "### Task 5 - Define the Model creation pipeline stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd747f-8fd1-4e69-bb2e-8c6788479cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SoundLevelDecibels\")\n",
    "lr2 = LinearRegression(featuresCol=\"features\", labelCol=\"SoundLevelDecibels\", \n",
    "                       regParam=1.0, elasticNetParam=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e4f34b-318c-41e7-937b-ce932ef9874b",
   "metadata": {},
   "source": [
    "### Task 6 - Build the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842de964-ad73-4f6f-b992-50a7b967cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "pipeline2 = Pipeline(stages=[assembler, scaler, lr2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ac0b8-bd82-4282-b0ea-2619e1eef7e1",
   "metadata": {},
   "source": [
    "### Task 7 - Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186215e-1c80-4da5-a275-6369c2784588",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testingData) = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc25227-1861-403d-9ac0-806d059c8cab",
   "metadata": {},
   "source": [
    "### Task 8 - Fit the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949e987-796f-4d0e-b57c-e4c6de6c2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(trainingData)\n",
    "pipelineModel2 = pipeline2.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0c24c-1bff-431e-a451-395dabbe0731",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41f11f-adfc-457f-a97e-dbca3b057a4a",
   "metadata": {},
   "source": [
    "### Task 1 - Predict using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc88b7f-ee91-4cc4-8ae8-fcd3ec55788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipelineModel.transform(testingData)\n",
    "predictions2 = pipelineModel2.transform(testingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c843c04-1fdb-40ed-88fc-2712a29ebca6",
   "metadata": {},
   "source": [
    "### Task 2 - Print the MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed00c59-ec3d-474a-936a-18a85d0260fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "mse2 = evaluator.evaluate(predictions2)\n",
    "print(f'MSE with Linear Regression: {mse}, MSE with Ridge Regression: {mse2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e3ebb-c244-4b14-a8dd-367dc4d318b3",
   "metadata": {},
   "source": [
    "### Task 3 - Print the MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdababd-1d82-403e-9b25-abe47707ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "mae2 = evaluator.evaluate(predictions2)\n",
    "print(f'MAE with Linear Regression: {mae}, MAE with Ridge Regression: {mae2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3488259-ec0b-4326-929b-37aee9838b2d",
   "metadata": {},
   "source": [
    "### Task 4 - Print the R-Squared(R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564d12d-8b32-4053-b9a4-1f1f99af186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "r2_2 = evaluator.evaluate(predictions2)\n",
    "print(f'R2 with Linear Regression: {r2}, R2 with Ridge Regression: {r2_2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8e7b5-a7c7-419b-841c-69185c7895da",
   "metadata": {},
   "source": [
    "## Part 4 - Persist the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e5ce8-1681-49b7-ad03-340bd8f14e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline model as \"Final_Project\"\n",
    "# your code goes here\n",
    "pipelineModel.write().overwrite().save(\"Final_Project_Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cd1d0-3315-4be2-a30b-7996da251e26",
   "metadata": {},
   "source": [
    "### Task 2 - Load the model from the path \"Final_Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eeeb47-4995-498c-8964-85d591232d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pipeline model you have created in the previous step\n",
    "from pyspark.ml import PipelineModel\n",
    "loadedPipelineModel = PipelineModel.load(\"Final_Project_Model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc40d9-64cc-4ce4-8613-983b5a941663",
   "metadata": {},
   "source": [
    "### Task 3 - Make predictions using the loaded model on the testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93908e06-2b76-4d78-80c3-f110139a272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded pipeline model and make predictions using testingData\n",
    "predictions = loadedPipelineModel.transform(testingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79111-d56a-4af1-9c61-a5e2fbab6655",
   "metadata": {},
   "source": [
    "### Task 4 - Show the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbe14d-0afd-4435-97b9-e36688a9421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show top 5 rows from the predections dataframe. Display only the label column and predictions\n",
    "#your code goes here\n",
    "predictions.select(\"SoundLevelDecibels\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f874216-a56a-468d-954d-53eeced9743f",
   "metadata": {},
   "source": [
    "### Stop Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78f8dd-2ad9-44ff-8c30-0d7d6ae1fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd2d36-67c2-4087-befb-697ffda81e15",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c469a6f-b2c9-46a3-add3-ef713a7a1568",
   "metadata": {},
   "source": [
    "<!--\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-05-26|0.1|Ramesh Sannareddy|Initial Version Created|\n",
    "-->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "prev_pub_hash": "7ade9c37d49d8d8ca6fc6e9e3c3b8b99b1549067e622440dcb8959d88a3508fd"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
